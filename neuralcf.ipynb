{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Basic workflow for the CIL Project 1\n- Modules built on pytorch_lightning for easier interface and logging capabilities\n- Important functionality logged to Wandb (See [this](https://wandb.ai/site/articles/pytorch-lightning-with-weights-biases) article for more information)\n- NeuMF mostly implemented except for the $\\alpha$ weighting in the paper\n- Probably overfits because the models map everyhing to the same entry $\\to$\n    - [x] add weight initialization (Added on May 12)\n    - todo: check gradients (maybe batch norm or LeakyRELU or parametric RELU would work better)\n- Todo: Check the validation in the sample code and find an effective way to incorporate it into pytorch lightning\n\n## Some thoughts\n- Vanilla NCF (given version) gets ~>0.90 training loss, ~1.02 valid loss\n- GMF, MLP and Vanilla losses seem to be stuck around 1.26, to improve we may try\n    - Getting 5 outputs (for rating$=1, 2, \\dots, 5$)\n    - Normalize the ratings (but still a narrow range may not help that much)\n    - [x] Add dropout => trained with p=0.2, validaiton rmse ~1.6, 0.1 doesn't seem so good either","metadata":{}},{"cell_type":"markdown","source":"# Quick Comments\n- For the current version, cpu does a fair enough job\n- MLP network is kind of customized version of NeuralCF\n\n## PytorchLightning\n- Models are defined with [pytorchlightning](https://www.pytorchlightning.ai/) which makes training and logging a lot easier.\n- It automatically disables batchnorm and dropout for eval mode\n\n## Wandb\n- First time: add your WANDB_API_KEY to kaggle secrets by going to Add-ons -> Secrets\n- `wandb.watch(model)` logs gradients of the model\n- Model name is useful to log the losses with their names in wandb\n- Call `wandb.finish()` every time a new trianing starts otherwise checkpoints are overwritten.\n- Made my wandb project open to public, you can monitor the results [here](https://wandb.ai/gsaltintas/cil-project/overview?workspace=user-gsaltintas)","metadata":{}},{"cell_type":"code","source":"! nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:43:56.553232Z","iopub.execute_input":"2022-05-13T14:43:56.554066Z","iopub.status.idle":"2022-05-13T14:43:57.338315Z","shell.execute_reply.started":"2022-05-13T14:43:56.553997Z","shell.execute_reply":"2022-05-13T14:43:57.337525Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# If not running in your local machine, you should install pytorch_lightning and wandb at the beginning of each execution\n! pip install pytorch_lightning wandb;","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:55:33.634354Z","iopub.execute_input":"2022-05-13T14:55:33.634790Z","iopub.status.idle":"2022-05-13T14:55:44.070884Z","shell.execute_reply.started":"2022-05-13T14:55:33.634738Z","shell.execute_reply":"2022-05-13T14:55:44.069183Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport json\nimport math\nimport time\n\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.loggers import WandbLogger\nimport wandb\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-13T14:44:09.608311Z","iopub.execute_input":"2022-05-13T14:44:09.608686Z","iopub.status.idle":"2022-05-13T14:44:14.543984Z","shell.execute_reply.started":"2022-05-13T14:44:09.608644Z","shell.execute_reply":"2022-05-13T14:44:14.542750Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# add your WANDB_API_KEY to kaggle secrets by going to Add-ons -> Secrets\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nWANDB_API_KEY = user_secrets.get_secret(\"WANDB_API_KEY\") \n# in a local computer add the following line to your bashrc or at the top of your notebook,\n# modify accordingly\n# os.environ['WANDB_API_KEY'] = 'WANDB_API_KEY'\n# you can also create wandb team and log the trainings there\n# gsaltintas/cil=project is now public so you can log there\nos.environ['WANDB_ENTITY'] = 'gsaltintas'\n# WANDB_API_KEY = os.environ['WANDB_API_KEY']","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:44:14.546895Z","iopub.execute_input":"2022-05-13T14:44:14.547480Z","iopub.status.idle":"2022-05-13T14:44:14.901292Z","shell.execute_reply.started":"2022-05-13T14:44:14.547428Z","shell.execute_reply":"2022-05-13T14:44:14.900093Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# this uses API key added to kaggle secrets\n! wandb login $WANDB_API_KEY","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:44:14.902846Z","iopub.execute_input":"2022-05-13T14:44:14.903179Z","iopub.status.idle":"2022-05-13T14:44:17.492566Z","shell.execute_reply.started":"2022-05-13T14:44:14.903140Z","shell.execute_reply":"2022-05-13T14:44:17.491402Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#  use gpu if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# necessary for trainer later\ngpus = [0] if torch.cuda.is_available() else None\nprint('Using device:', device)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:44:17.494819Z","iopub.execute_input":"2022-05-13T14:44:17.495092Z","iopub.status.idle":"2022-05-13T14:44:17.501758Z","shell.execute_reply.started":"2022-05-13T14:44:17.495052Z","shell.execute_reply":"2022-05-13T14:44:17.500972Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation\nSame as template code","metadata":{}},{"cell_type":"code","source":"number_of_users, number_of_movies = (10000, 1000)\n\ndata_pd = pd.read_csv('/kaggle/input/cil-collaborative-filtering-2022/data_train.csv')\ntest_pd = pd.read_csv('/kaggle/input/cil-collaborative-filtering-2022/sampleSubmission.csv')\nprint(data_pd.head(5))\nprint(test_pd.head(5))\nprint()\nprint('Shape', data_pd.shape, test_pd.shape, data_pd.shape[0]/test_pd.shape[0])","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:44:17.502893Z","iopub.execute_input":"2022-05-13T14:44:17.503163Z","iopub.status.idle":"2022-05-13T14:44:19.654069Z","shell.execute_reply.started":"2022-05-13T14:44:17.503132Z","shell.execute_reply":"2022-05-13T14:44:19.653069Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# Split the dataset into train and test\n\ntrain_size = 0.9\n\ntrain_pd, test_pd = train_test_split(data_pd, train_size=train_size, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:44:19.655380Z","iopub.execute_input":"2022-05-13T14:44:19.655625Z","iopub.status.idle":"2022-05-13T14:44:21.419547Z","shell.execute_reply.started":"2022-05-13T14:44:19.655596Z","shell.execute_reply":"2022-05-13T14:44:21.417758Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def extract_users_items_predictions(data_pd):\n    users, movies = \\\n        [np.squeeze(arr) for arr in np.split(data_pd.Id.str.extract('r(\\d+)_c(\\d+)').values.astype(int) - 1, 2, axis=-1)]\n    predictions = data_pd.Prediction.values\n    return users, movies, predictions\n\ntrain_users, train_movies, train_predictions = extract_users_items_predictions(train_pd)\n\n# also create full matrix of observed values\ndata = np.full((number_of_users, number_of_movies), np.mean(train_pd.Prediction.values))\nmask = np.zeros((number_of_users, number_of_movies)) # 0 -> unobserved value, 1->observed value\n\nfor user, movie, pred in zip(train_users, train_movies, train_predictions):\n    data[user - 1][movie - 1] = pred\n    mask[user - 1][movie - 1] = 1","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:44:21.422189Z","iopub.execute_input":"2022-05-13T14:44:21.422480Z","iopub.status.idle":"2022-05-13T14:44:30.081875Z","shell.execute_reply.started":"2022-05-13T14:44:21.422449Z","shell.execute_reply":"2022-05-13T14:44:30.080962Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:44:30.083293Z","iopub.execute_input":"2022-05-13T14:44:30.083626Z","iopub.status.idle":"2022-05-13T14:44:30.093312Z","shell.execute_reply.started":"2022-05-13T14:44:30.083583Z","shell.execute_reply":"2022-05-13T14:44:30.092143Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nrmse = lambda x, y: math.sqrt(mean_squared_error(x, y))\n\ntest_users, test_movies, test_predictions = extract_users_items_predictions(test_pd)\n\n# test our predictions with the true values\ndef get_score(predictions, target_values=test_predictions):\n    return rmse(predictions, target_values)\n\ndef extract_prediction_from_full_matrix(reconstructed_matrix, users=test_users, movies=test_movies):\n    # returns predictions for the users-movies combinations specified based on a full m \\times n matrix\n    assert(len(users) == len(movies)), \"users-movies combinations specified should have equal length\"\n    predictions = np.zeros(len(test_users))\n\n    for i, (user, movie) in enumerate(zip(users, movies)):\n        predictions[i] = reconstructed_matrix[user][movie]\n\n    return predictions\n\ndef mse_loss(predictions, target):\n    return torch.mean((predictions - target) ** 2)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:44:30.094838Z","iopub.execute_input":"2022-05-13T14:44:30.095101Z","iopub.status.idle":"2022-05-13T14:44:30.657613Z","shell.execute_reply.started":"2022-05-13T14:44:30.095068Z","shell.execute_reply":"2022-05-13T14:44:30.656667Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Neural CF\nDefine models","metadata":{}},{"cell_type":"code","source":"# initialize with Gaussian distribution (0, 0.01)\ndef initialize_weights(model, mean=0, std=0.01):\n    if isinstance(model, nn.Linear):\n        nn.init.normal_(model.weight, mean, std)\n    if isinstance(model, nn.BatchNorm1d):\n        nn.init.normal_(model.weight, mean, std)\n        nn.init.constant_(model.bias, mean)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:44:30.659571Z","iopub.execute_input":"2022-05-13T14:44:30.659856Z","iopub.status.idle":"2022-05-13T14:44:30.665430Z","shell.execute_reply.started":"2022-05-13T14:44:30.659823Z","shell.execute_reply":"2022-05-13T14:44:30.664781Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"class BaseNCF(pl.LightningModule):\n    \"\"\" This is the BaseClass for underlying models, defines training and validation functionality, \n    and Adam optimizer\n    \"\"\"\n    def __init__(self, number_of_users, number_of_movies, embedding_size,                 \n                 lr: float = 0.001,\n                b1: float = 0.5,\n                b2: float = 0.999,\n                momentum: float = 0.9,\n                loss_func = mse_loss,\n                sublayer_name :str = ''):\n        \"\"\"\n        @param loss_func: specify the loss function for modularity, by default mse_loss\n        @param sublayer_name: useful for logging\n        \"\"\"\n        super().__init__()\n        self.save_hyperparameters()\n        self.embedding_layer_users = nn.Embedding(number_of_users, embedding_size)\n        self.embedding_layer_movies = nn.Embedding(number_of_movies, embedding_size)\n        self.loss_func = loss_func\n        \n\n        self.feed_forward = nn.Sequential(\n            nn.Linear(in_features=2 * embedding_size, out_features=64),\n            nn.ReLU(),\n            nn.Linear(in_features=64, out_features=16),\n            nn.ReLU(),\n            nn.Linear(in_features=16, out_features=1), # maybe predict per category?\n            nn.ReLU()\n        )\n        \n    def forward(self, users, movies):\n        raise ('Must be implemented by subclasses')\n    \n    def training_step(self, batch, batch_idx):\n        users, movies, ratings = batch\n        predictions = self(users, movies)\n        loss = self.loss_func(predictions, ratings)\n        self.log(f'{self.hparams.sublayer_name}/train_loss', loss)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        users, movies, ratings = batch\n        predictions = self(users, movies)\n        loss = self.loss_func(predictions, ratings)\n        self.log(f'{self.hparams.sublayer_name}/valid_loss', loss)\n        return loss\n    \n    def configure_optimizers(self):\n        lr = self.hparams.lr\n        b1 = self.hparams.b1\n        b2 = self.hparams.b2\n        weight_decay = 5*1e-4 \n        opt = torch.optim.Adam(self.parameters(), lr=lr, betas=(b1, b2), weight_decay= weight_decay)\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(opt,T_0=1, T_mult = 2,\n                                                             eta_min=1e-7)\n        return {\"optimizer\": opt,\n                \"lr_scheduler\": {\n                    \"scheduler\": scheduler,\n                    \"monitor\": \"val_loss\"\n                },\n               }\n    \n    def predict_step(self, batch, batch_idx):\n        users, movies = batch\n        return self(users, movies)\n    \n    def name(self):\n#         todo: name model for saving purposes\n        return f\"BaseNCF_{'Adam'}\"\n\nclass Vanilla_NCF(BaseNCF):\n    \"\"\" VanillaNCF class as implemented in the sample code \"\"\"\n    def __init__(self, number_of_users, number_of_movies, embedding_size,                 \n                 sublayer_name='vanilla_ncf',\n                 *args, **kwargs):\n        super().__init__( number_of_users, number_of_movies, embedding_size, *args, **kwargs)\n        self.embedding_layer_users = nn.Embedding(number_of_users, embedding_size)\n        self.embedding_layer_movies = nn.Embedding(number_of_movies, embedding_size)\n        \n        self.feed_forward = nn.Sequential(\n            nn.Linear(in_features=2 * embedding_size, out_features=64),\n            nn.ReLU(),\n            nn.Linear(in_features=64, out_features=16),\n            nn.ReLU(),\n            nn.Linear(in_features=16, out_features=1), # maybe predict per category?\n            nn.ReLU()\n        )\n\n    def forward(self, users, movies):\n        users_embedding = self.embedding_layer_users(users)\n        movies_embedding = self.embedding_layer_movies(movies)\n        concat = torch.cat([users_embedding, movies_embedding], dim=1)\n        return torch.squeeze(self.feed_forward(concat))\n    \n   \n    def name(self):\n        return f\"Vanilla_NCF_{'Adam'}\"\n    \n    def configure_optimizers(self):\n        lr = self.hparams.lr\n        opt = torch.optim.Adam(self.parameters(), lr=lr)\n        \n        return {\"optimizer\": opt,}","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:45:05.256112Z","iopub.execute_input":"2022-05-13T14:45:05.256467Z","iopub.status.idle":"2022-05-13T14:45:05.280717Z","shell.execute_reply.started":"2022-05-13T14:45:05.256431Z","shell.execute_reply":"2022-05-13T14:45:05.279446Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"class GMF(BaseNCF):\n    \"\"\" Generalized Matrix Factoization network as described in the paper \"\"\"\n    def __init__(self, number_of_users, number_of_movies, embedding_size,\n                 sublayer_name='gmf',\n                 *args, **kwargs):\n        super(GMF, self).__init__(number_of_users, number_of_movies, embedding_size,)\n        self.embedding_layer_users = nn.Embedding(number_of_users, embedding_size)\n        self.embedding_layer_movies = nn.Embedding(number_of_movies, embedding_size)\n        self.output_layer = nn.Linear(in_features=embedding_size, out_features=1)\n        \n    def forward(self, users, movies):\n        users_embedding = self.embedding_layer_users(users)\n        movies_embedding = self.embedding_layer_movies(movies)\n        return self.output_layer(users_embedding * movies_embedding)    ","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:45:08.908202Z","iopub.execute_input":"2022-05-13T14:45:08.908538Z","iopub.status.idle":"2022-05-13T14:45:08.916069Z","shell.execute_reply.started":"2022-05-13T14:45:08.908506Z","shell.execute_reply":"2022-05-13T14:45:08.915235Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"class MLP(BaseNCF):\n    \"\"\" MLP network of NeuMF modified from the paper (BatchNorm added, Leaky ReLU instead of RELU)\"\"\"\n    def __init__(self, number_of_users, number_of_movies, embedding_size,\n                 layer_sizes=[64, 32, 16, 8], # may be used to define feed_forward layer in a more sophisticated way\n                 sublayer_name='mlp',\n                 dropout: float = 0,\n                 *args, **kwargs):\n        \"\"\"\n        dropout: dropout probability, by default 0\n        \"\"\"\n        super(MLP, self).__init__(number_of_users, number_of_movies, embedding_size,)\n        self.embedding_layer_users = nn.Embedding(number_of_users, embedding_size)\n        self.embedding_layer_movies = nn.Embedding(number_of_movies, embedding_size)\n        \n        self.feed_forward = nn.Sequential(\n            nn.Linear(in_features=2 * embedding_size, out_features=64),\n            nn.BatchNorm1d(num_features=64),\n            nn.Dropout(dropout),\n            nn.LeakyReLU(),\n            nn.Linear(in_features=64, out_features=16), \n            nn.BatchNorm1d(num_features=16),\n            nn.Dropout(dropout),\n            nn.LeakyReLU(),\n            nn.Linear(in_features=16, out_features=1), \n            nn.Dropout(dropout),\n            nn.LeakyReLU()\n        )\n\n        \n    def forward(self, users, movies):\n        users_embedding = self.embedding_layer_users(users)\n        movies_embedding = self.embedding_layer_movies(movies)\n        concat = torch.cat([users_embedding, movies_embedding], dim=1)\n        hidden_layers = torch.squeeze(self.feed_forward(concat)) \n        return hidden_layers\n   ","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:45:09.111384Z","iopub.execute_input":"2022-05-13T14:45:09.111949Z","iopub.status.idle":"2022-05-13T14:45:09.122432Z","shell.execute_reply.started":"2022-05-13T14:45:09.111913Z","shell.execute_reply":"2022-05-13T14:45:09.121536Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"class MultiModalMLP(BaseNCF):\n    \"\"\" TODO: MLP network for multiclass classification  \"\"\"\n    def __init__(self, number_of_users, number_of_movies, embedding_size,\n                 layer_sizes=[64, 32, 16, 8], # may be used to define feed_forward layer in a more sophisticated way\n                 sublayer_name='multimodal_mlp',\n                 *args, **kwargs):\n        super(MultiModalMLP, self).__init__(number_of_users, number_of_movies, embedding_size,)\n        self.embedding_layer_users = nn.Embedding(number_of_users, embedding_size)\n        self.embedding_layer_movies = nn.Embedding(number_of_movies, embedding_size)\n        \n        self.feed_forward = nn.Sequential(\n            nn.Linear(in_features=2 * embedding_size, out_features=64),\n            nn.LeakyReLU(),\n            nn.Linear(in_features=64, out_features=32),\n            nn.LeakyReLU(),\n            nn.Linear(in_features=32, out_features=16), # maybe predict per category?\n            nn.LeakyReLU(),\n#             nn.Linear(in_features=16, out_features=5), \n#             nn.LeakyReLU()\n        )\n#         self.output_layer = nn.Linear(8, 1)\n        self.output_layer = nn.Linear(16, 5)\n        \n    def forward(self, users, movies):\n        users_embedding = self.embedding_layer_users(users)\n        movies_embedding = self.embedding_layer_movies(movies)\n        concat = torch.cat([users_embedding, movies_embedding], dim=1)\n        hidden_layers = torch.squeeze(self.feed_forward(concat)) \n        return self.output_layer(hidden_layers)\n   ","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:45:09.611341Z","iopub.execute_input":"2022-05-13T14:45:09.611646Z","iopub.status.idle":"2022-05-13T14:45:09.622604Z","shell.execute_reply.started":"2022-05-13T14:45:09.611612Z","shell.execute_reply":"2022-05-13T14:45:09.621644Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"class NeuMF(BaseNCF):\n    def __init__(self, number_of_users, number_of_movies, embedding_size,                 \n                 lr: float = 0.001,\n                 alpha = 0.5, # trade-off parameter between two models\n                 gmf_pretrained_ckpt = '',\n                 mlp_pretrained_ckpt = '',\n                 sublayer_name='neumf',\n                 *args, **kwargs):\n        super().__init__( number_of_users, number_of_movies, embedding_size,)\n        \n        self.gmf = GMF.load_from_checkpoint(gmf_pretrained_ckpt); self.gmf.mode = 'train'\n        self.mlp = MLP.load_from_checkpoint(mlp_pretrained_ckpt); self.mlp.mode = 'train'\n        self.output_layer = nn.Linear(in_features=2, out_features=1)\n\n    def forward(self, users, movies):\n        gmf = self.gmf(users, movies)\n        mlp = self.mlp(users, movies)\n        concat = torch.cat([gmf, mlp], dim=1)\n#         todo: implement \\alpha later\n        return self.output_layer(concat)\n    \n   \n    def name(self):\n        return f\"Full_NCF_{'VanillaSGD'}\"\n    \n     \n    # The paper uses VanillaSGD at this layer as they start the GMF and MLP layers pretrained\n    def configure_optimizers(self):\n        lr = self.hparams.lr\n        opt = torch.optim.SGD(self.parameters(), lr=lr)\n        return {\"optimizer\": opt}\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:45:09.955819Z","iopub.execute_input":"2022-05-13T14:45:09.956099Z","iopub.status.idle":"2022-05-13T14:45:09.967153Z","shell.execute_reply.started":"2022-05-13T14:45:09.956070Z","shell.execute_reply":"2022-05-13T14:45:09.966181Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"# Pretraining & Setup\nPretrain GMF and MLP layers\n\nNOTE: In the sample code, they reform the matrix and calculate a different metric at the end of each epoch, we don't do that currently and only calculate validation loss on a batch.","metadata":{}},{"cell_type":"code","source":"# Parameters\nbatch_size = 1024\nvalid_batch_size = 1024\nnum_epochs = 25\nshow_validation_score_every_epochs = 1\nembedding_size = 16\nlearning_rate = 1e-3\npretrain = True","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:45:11.357448Z","iopub.execute_input":"2022-05-13T14:45:11.358010Z","iopub.status.idle":"2022-05-13T14:45:11.362001Z","shell.execute_reply.started":"2022-05-13T14:45:11.357973Z","shell.execute_reply":"2022-05-13T14:45:11.361323Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# Build Dataloaders\ntrain_users_torch = torch.tensor(train_users, device=device)\ntrain_movies_torch = torch.tensor(train_movies, device=device)\ntrain_predictions_torch = torch.tensor(train_predictions, device=device)\n\ntrain_dataloader = DataLoader(\n#     todo: try normalizing for the inputs\n    TensorDataset(train_users_torch, train_movies_torch, train_predictions_torch),\n    batch_size=batch_size)\n\ntest_users_torch = torch.tensor(test_users, device=device)\ntest_movies_torch = torch.tensor(test_movies, device=device)\ntest_predictions_torch = torch.tensor(test_predictions, device=device)\n\ntest_dataloader = DataLoader(\n    TensorDataset(test_users_torch, test_movies_torch, test_predictions_torch),\n    batch_size=valid_batch_size)\n\nwandb_logger = WandbLogger(project='cil-project',\n                           log_model='all', \n                           )\nlr_monitor = pl.callbacks.LearningRateMonitor(logging_interval='step')\n# saves a file like: my/path/sample-mnist-epoch=02-val_loss=0.32.ckpt\ncheckpoint_callback = pl.callbacks.ModelCheckpoint(\n    monitor=\"valid_loss\",\n    save_top_k=2,\n    mode=\"min\",\n)\ntrainer = pl.Trainer(callbacks=[checkpoint_callback, lr_monitor], \n                     gpus=gpus, auto_select_gpus=True,\n                     max_epochs=num_epochs, \n                     auto_lr_find=True,\n                     logger=wandb_logger,\n                     log_every_n_steps=5,\n                    )","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:45:12.810504Z","iopub.execute_input":"2022-05-13T14:45:12.811014Z","iopub.status.idle":"2022-05-13T14:45:12.833637Z","shell.execute_reply.started":"2022-05-13T14:45:12.810979Z","shell.execute_reply":"2022-05-13T14:45:12.832782Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# when implemented, multimodal mlp can be defined here\n# multi = MultiModalMLP(number_of_users, number_of_movies, embedding_size,\n#          loss_func=mse_loss).to(device)\n# initialize_weights(multi, 0, 0.01)\n\n# # wandb.finish()\n# wandb_logger = WandbLogger(project='cil-project',\n#                            log_model='all', \n#                            name=f'multi_{time.time():.0f}'\n#                            )\n# # uncomment to log gradients\n# wandb_logger.watch(multi)\n\n# checkpoint_callback = pl.callbacks.ModelCheckpoint(\n#     monitor=\"multimodal_mlp/valid_loss\",\n#     save_top_k=2,\n#     mode=\"min\",\n# )\n# trainer = pl.Trainer(callbacks=[checkpoint_callback, lr_monitor], \n# #                      gpus=list(range(torch.cuda.device_count())), \n#                      gpus=gpus, auto_select_gpus=True,\n#                      max_epochs=num_epochs, \n#                      auto_lr_find=True,\n#                      logger=wandb_logger,\n#                      log_every_n_steps=5,\n#                     )","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:44:37.114619Z","iopub.execute_input":"2022-05-13T14:44:37.115592Z","iopub.status.idle":"2022-05-13T14:44:37.120991Z","shell.execute_reply.started":"2022-05-13T14:44:37.115534Z","shell.execute_reply":"2022-05-13T14:44:37.120017Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# trainer.fit(multi, train_dataloader, test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:44:37.421049Z","iopub.execute_input":"2022-05-13T14:44:37.421500Z","iopub.status.idle":"2022-05-13T14:44:37.425563Z","shell.execute_reply.started":"2022-05-13T14:44:37.421467Z","shell.execute_reply":"2022-05-13T14:44:37.424685Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## VanillaNCF\nUncomment to train VanillaNCF as presented in the sample notebook","metadata":{}},{"cell_type":"code","source":"ncf = Vanilla_NCF(number_of_users, number_of_movies, embedding_size*4,\n         loss_func=mse_loss).to(device)\ninitialize_weights(ncf, 0, 0.01)\n\nwandb.finish()\nwandb_logger = WandbLogger(project='cil-project',\n                           log_model='all', \n                           name=f'vanilla_ncf_{time.time():.0f}'\n                           )\n# uncomment to log gradients\nwandb_logger.watch(ncf)\n\ncheckpoint_callback = pl.callbacks.ModelCheckpoint(\n    monitor=\"vanilla_ncf/valid_loss\",\n    save_top_k=2,\n    mode=\"min\",\n)\ntrainer = pl.Trainer(callbacks=[checkpoint_callback, lr_monitor], \n                     gpus=gpus, auto_select_gpus=True,\n                     max_epochs=num_epochs, \n                     auto_lr_find=True,\n                     logger=wandb_logger,\n                     log_every_n_steps=5,\n                    )","metadata":{"execution":{"iopub.status.busy":"2022-05-13T11:37:35.563917Z","iopub.execute_input":"2022-05-13T11:37:35.564288Z","iopub.status.idle":"2022-05-13T11:37:48.587763Z","shell.execute_reply.started":"2022-05-13T11:37:35.564244Z","shell.execute_reply":"2022-05-13T11:37:48.586839Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"if True:\n    trainer.fit(ncf, train_dataloader, test_dataloader)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-05-13T11:39:43.183030Z","iopub.execute_input":"2022-05-13T11:39:43.183414Z","iopub.status.idle":"2022-05-13T11:52:57.827463Z","shell.execute_reply.started":"2022-05-13T11:39:43.183373Z","shell.execute_reply":"2022-05-13T11:52:57.826572Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"## Define & Pretrain GMF","metadata":{}},{"cell_type":"code","source":"gmf = GMF(number_of_users, number_of_movies, embedding_size,\n         loss_func=mse_loss).to(device)\ninitialize_weights(gmf, 0, 0.01)\n\nwandb.finish()\nwandb_logger = WandbLogger(project='cil-project',\n                           log_model='all', \n                           name=f'gmf_{time.time():.0f}'\n                           )\ncheckpoint_callback = pl.callbacks.ModelCheckpoint(\n    monitor=\"gmf/valid_loss\",\n    save_top_k=2,\n    mode=\"min\",\n)\ntrainer = pl.Trainer(callbacks=[checkpoint_callback, lr_monitor], \n                     gpus=gpus, auto_select_gpus=True,\n                     max_epochs=num_epochs, \n                     auto_lr_find=True,\n                     logger=wandb_logger,\n                     log_every_n_steps=5,\n                    )","metadata":{"execution":{"iopub.status.busy":"2022-05-12T09:35:31.240576Z","iopub.execute_input":"2022-05-12T09:35:31.240832Z","iopub.status.idle":"2022-05-12T09:36:01.627137Z","shell.execute_reply.started":"2022-05-12T09:35:31.240803Z","shell.execute_reply":"2022-05-12T09:36:01.626547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if pretrain:\n    print('Starting pretraining GMF module')\n    trainer.fit(gmf,  train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\nelse:\n    print('GMF pretraining skipped')","metadata":{"execution":{"iopub.status.busy":"2022-05-12T09:36:01.628662Z","iopub.execute_input":"2022-05-12T09:36:01.62908Z","iopub.status.idle":"2022-05-12T09:50:31.867834Z","shell.execute_reply.started":"2022-05-12T09:36:01.62905Z","shell.execute_reply":"2022-05-12T09:50:31.866312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define & Pretrain MLP","metadata":{}},{"cell_type":"code","source":"mlp = MLP(number_of_users, number_of_movies, embedding_size*2,\n         loss_func=mse_loss, dropout=0.1).to(device)\ninitialize_weights(mlp, 0, 0.01)\n\nwandb.finish()\nwandb_logger = WandbLogger(project='cil-project',\n                           log_model='all', \n                           name=f'mlp_{time.time():.0f}'\n                           )\ncheckpoint_callback = pl.callbacks.ModelCheckpoint(\n    monitor=\"mlp/valid_loss\",\n    save_top_k=2,\n    mode=\"min\",\n)\n\ntrainer = pl.Trainer(callbacks=[checkpoint_callback, lr_monitor], \n                     gpus=gpus, auto_select_gpus=True,\n                     max_epochs=num_epochs, \n                     auto_lr_find=True,\n                     logger=wandb_logger,\n                     log_every_n_steps=5,\n                    )","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:55:44.072854Z","iopub.execute_input":"2022-05-13T14:55:44.073152Z","iopub.status.idle":"2022-05-13T14:55:59.772349Z","shell.execute_reply.started":"2022-05-13T14:55:44.073110Z","shell.execute_reply":"2022-05-13T14:55:59.771280Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"if pretrain:\n    print('Starting MLP pretraining.')\n    trainer.fit(mlp,  train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\nelse:\n    print('MLP pretraining passed.')","metadata":{"execution":{"iopub.status.busy":"2022-05-13T14:55:59.773689Z","iopub.execute_input":"2022-05-13T14:55:59.774004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Uncomment when running for the first time in a scheduler, so that when this notebook fails \n# go to wandb, check the artifact to use and update \n# corresponding field in NeuMF layer\nassert not pretrain, 'Pretrain mode is on, not continuing with NeuMF training'","metadata":{"execution":{"iopub.status.busy":"2022-05-12T10:12:55.205222Z","iopub.execute_input":"2022-05-12T10:12:55.205458Z","iopub.status.idle":"2022-05-12T10:12:55.209341Z","shell.execute_reply.started":"2022-05-12T10:12:55.205431Z","shell.execute_reply":"2022-05-12T10:12:55.208526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NeuMF Layer\nDownload pretrained weights and initialize NeuMF layer and train on that","metadata":{}},{"cell_type":"code","source":"wandb.finish()\nrun = wandb.init(project='cil-project')\ngmf_artifact = run.use_artifact(f\"{os.environ['WANDB_ENTITY']}/cil-project/model-26mwkhfd:v10\", type='model')\nmlp_artifact = run.use_artifact(f\"{os.environ['WANDB_ENTITY']}/cil-project/model-9cngz9p3:v5\", type='model')\ngmf_artifact_dir = gmf_artifact.download()\nmlp_artifact_dir = mlp_artifact.download()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-13T13:09:39.283803Z","iopub.execute_input":"2022-05-13T13:09:39.284683Z","iopub.status.idle":"2022-05-13T13:09:54.374850Z","shell.execute_reply.started":"2022-05-13T13:09:39.284632Z","shell.execute_reply":"2022-05-13T13:09:54.373613Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"os.listdir(gmf_artifact_dir)\nos.path.abspath(os.path.join(gmf_artifact_dir, 'model.ckpt'))","metadata":{"execution":{"iopub.status.busy":"2022-05-13T13:09:54.377168Z","iopub.execute_input":"2022-05-13T13:09:54.377662Z","iopub.status.idle":"2022-05-13T13:09:54.831123Z","shell.execute_reply.started":"2022-05-13T13:09:54.377620Z","shell.execute_reply":"2022-05-13T13:09:54.829583Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"model = NeuMF(number_of_users, number_of_movies, embedding_size,\n              gmf_pretrained_ckpt=os.path.abspath(os.path.join(gmf_artifact_dir, 'model.ckpt')),\n              mlp_pretrained_ckpt=os.path.abspath(os.path.join(mlp_artifact_dir, 'model.ckpt')),\n             loss_func=mse_loss).to(device)\nwandb.watch(model)\n\nwandb_logger = WandbLogger(project='cil-project',\n                           log_model='all', \n                           name=run\n                           )\ncheckpoint_callback = pl.callbacks.ModelCheckpoint(\n    monitor=\"neumf/valid_loss\",\n    save_top_k=2,\n    mode=\"min\",\n)\ntrainer = pl.Trainer(callbacks=[checkpoint_callback, lr_monitor], \n                     gpus=gpus, auto_select_gpus=True,\n                     max_epochs=num_epochs, \n                     auto_lr_find=True,\n                     logger=wandb_logger,\n                     log_every_n_steps=5,\n                    )","metadata":{"execution":{"iopub.status.busy":"2022-05-13T13:09:54.833125Z","iopub.execute_input":"2022-05-13T13:09:54.834277Z","iopub.status.idle":"2022-05-13T13:09:55.245349Z","shell.execute_reply.started":"2022-05-13T13:09:54.834218Z","shell.execute_reply":"2022-05-13T13:09:55.244592Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-05-12T10:15:59.085535Z","iopub.execute_input":"2022-05-12T10:15:59.086129Z","iopub.status.idle":"2022-05-12T10:20:11.661998Z","shell.execute_reply.started":"2022-05-12T10:15:59.086089Z","shell.execute_reply":"2022-05-12T10:20:11.661041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit\n## Submission Predictions","metadata":{}},{"cell_type":"code","source":"submission_pd = pd.read_csv('/kaggle/input/cil-collaborative-filtering-2022/sampleSubmission.csv')\nsubmission_users, submission_movies, submission_ratings = extract_users_items_predictions(submission_pd)\nsubmission_users_torch = torch.tensor(submission_users, device=device)\nsubmission_movies_torch = torch.tensor(submission_movies, device=device)\n# create submission dataloader\nsubmit_loader = DataLoader(TensorDataset(submission_users_torch, submission_movies_torch),\n                          batch_size=batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict entries using trainer\nsubmission_predictions = trainer.predict(model, submit_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit\nTransfer predictions for each batch to the data frame (can use model(batch) then trainer.predict for memory efficiency) and then write it to csv.","metadata":{}},{"cell_type":"code","source":"submission_i = 0\nfor pred_batch in submission_predictions:\n    start_ind = submission_i*batch_size\n    end_ind = pred_batch.shape[0] + start_ind\n    preds_cpu = np.array(pred_batch.cpu())\n    np.clip(preds_cpu, a_min=1, a_max=5, out=preds_cpu)\n    submission_pd.iloc[start_ind: end_ind, 1] = preds_cpu\n    submission_i += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_pd.head, submission_pd.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_name = 'mlp_embedding2_dropout_submission.csv'\nsubmission_pd.to_csv(file_name, encoding='utf-8', index=False)\n# just in case upload submission to wandb\nwandb.save(file_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sanity check\n! head *.csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create download link\nfrom IPython.display import FileLink \nFileLink(file_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}