{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Basic workflow for the CIL Project 1\n- Modules built on pytorch_lightning for easier interface and logging capabilities\n- Important functionality logged to Wandb (See [this](https://wandb.ai/site/articles/pytorch-lightning-with-weights-biases) article for more information)\n- NeuMF mostly implemented except for the $\\alpha$ weighting in the paper\n- Probably overfits because the models map everyhing to the same entry -> \n    - todo: add weight initialization\n    - todo: check gradients (maybe batch norm or LeakyRELU or parametric RELU would work better)\n- Todo: Check the validation in the sample code and find an effective way to incorporate it into pytorch lightning\n- GPU: Comment off `gpu=` part in the trainer definition if GPU not available","metadata":{}},{"cell_type":"code","source":"! pip install pytorch_lightning;","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:03:26.693436Z","iopub.execute_input":"2022-04-30T22:03:26.693927Z","iopub.status.idle":"2022-04-30T22:03:36.379689Z","shell.execute_reply.started":"2022-04-30T22:03:26.693841Z","shell.execute_reply":"2022-04-30T22:03:36.378773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport json\nimport math\n\n\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, TensorDataset\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.loggers import WandbLogger\nimport wandb\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-30T22:03:36.381872Z","iopub.execute_input":"2022-04-30T22:03:36.382144Z","iopub.status.idle":"2022-04-30T22:03:39.879635Z","shell.execute_reply.started":"2022-04-30T22:03:36.382109Z","shell.execute_reply":"2022-04-30T22:03:39.878823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# add your WANDB_API_KEY to kaggle secrets by going to Add-ons -> Secrets\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nWANDB_API_KEY = user_secrets.get_secret(\"WANDB_API_KEY\") \n# in a local computer add the following line to your bashrc or at the top of your notebook\n# export WANDB_API_KEY=\"WANDB_API_KEY\"\n# WANDB_API_KEY = os.environ['WANDB_API_KEY']","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:41:48.77644Z","iopub.execute_input":"2022-04-30T22:41:48.777129Z","iopub.status.idle":"2022-04-30T22:41:50.874144Z","shell.execute_reply.started":"2022-04-30T22:41:48.77709Z","shell.execute_reply":"2022-04-30T22:41:50.873271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this uses API key added to kaggle secrets\n! wandb login $WANDB_API_KEY","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:03:40.439672Z","iopub.execute_input":"2022-04-30T22:03:40.439877Z","iopub.status.idle":"2022-04-30T22:03:42.433933Z","shell.execute_reply.started":"2022-04-30T22:03:40.439851Z","shell.execute_reply":"2022-04-30T22:03:42.433124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  use gpu if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint('Using device:', device)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:03:42.437222Z","iopub.execute_input":"2022-04-30T22:03:42.437531Z","iopub.status.idle":"2022-04-30T22:03:42.496471Z","shell.execute_reply.started":"2022-04-30T22:03:42.437501Z","shell.execute_reply":"2022-04-30T22:03:42.495769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number_of_users, number_of_movies = (10000, 1000)\n\ndata_pd = pd.read_csv('/kaggle/input/cil-collaborative-filtering-2022/data_train.csv')\ntest_pd = pd.read_csv('/kaggle/input/cil-collaborative-filtering-2022/sampleSubmission.csv')\nprint(data_pd.head(5))\nprint(test_pd.head(5))\nprint()\nprint('Shape', data_pd.shape, test_pd.shape, data_pd.shape[0]/test_pd.shape[0])","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:03:42.498878Z","iopub.execute_input":"2022-04-30T22:03:42.499504Z","iopub.status.idle":"2022-04-30T22:03:44.165814Z","shell.execute_reply.started":"2022-04-30T22:03:42.499466Z","shell.execute_reply":"2022-04-30T22:03:44.165087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n# Split the dataset into train and test\n\ntrain_size = 0.9\n\ntrain_pd, test_pd = train_test_split(data_pd, train_size=train_size, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:03:44.166924Z","iopub.execute_input":"2022-04-30T22:03:44.167162Z","iopub.status.idle":"2022-04-30T22:03:45.193169Z","shell.execute_reply.started":"2022-04-30T22:03:44.167127Z","shell.execute_reply":"2022-04-30T22:03:45.192431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def extract_users_items_predictions(data_pd):\n    users, movies = \\\n        [np.squeeze(arr) for arr in np.split(data_pd.Id.str.extract('r(\\d+)_c(\\d+)').values.astype(int) - 1, 2, axis=-1)]\n    predictions = data_pd.Prediction.values\n    return users, movies, predictions\n\ntrain_users, train_movies, train_predictions = extract_users_items_predictions(train_pd)\n\n# also create full matrix of observed values\ndata = np.full((number_of_users, number_of_movies), np.mean(train_pd.Prediction.values))\nmask = np.zeros((number_of_users, number_of_movies)) # 0 -> unobserved value, 1->observed value\n\nfor user, movie, pred in zip(train_users, train_movies, train_predictions):\n    data[user - 1][movie - 1] = pred\n    mask[user - 1][movie - 1] = 1","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:03:45.194397Z","iopub.execute_input":"2022-04-30T22:03:45.194693Z","iopub.status.idle":"2022-04-30T22:03:52.491425Z","shell.execute_reply.started":"2022-04-30T22:03:45.194659Z","shell.execute_reply":"2022-04-30T22:03:52.490678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:03:52.492776Z","iopub.execute_input":"2022-04-30T22:03:52.493029Z","iopub.status.idle":"2022-04-30T22:03:52.501005Z","shell.execute_reply.started":"2022-04-30T22:03:52.492994Z","shell.execute_reply":"2022-04-30T22:03:52.500332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nrmse = lambda x, y: math.sqrt(mean_squared_error(x, y))\n\ntest_users, test_movies, test_predictions = extract_users_items_predictions(test_pd)\n\n# test our predictions with the true values\ndef get_score(predictions, target_values=test_predictions):\n    return rmse(predictions, target_values)\n\ndef extract_prediction_from_full_matrix(reconstructed_matrix, users=test_users, movies=test_movies):\n    # returns predictions for the users-movies combinations specified based on a full m \\times n matrix\n    assert(len(users) == len(movies)), \"users-movies combinations specified should have equal length\"\n    predictions = np.zeros(len(test_users))\n\n    for i, (user, movie) in enumerate(zip(users, movies)):\n        predictions[i] = reconstructed_matrix[user][movie]\n\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:03:52.50326Z","iopub.execute_input":"2022-04-30T22:03:52.503689Z","iopub.status.idle":"2022-04-30T22:03:52.955679Z","shell.execute_reply.started":"2022-04-30T22:03:52.503653Z","shell.execute_reply":"2022-04-30T22:03:52.95491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Neural CF\nDefine models","metadata":{}},{"cell_type":"code","source":"class BaseNCF(pl.LightningModule):\n    \"\"\" This is the BaseClass for underlying models, defines training and validation functionality, \n    and Adam optimizer\n    \"\"\"\n    def __init__(self, number_of_users, number_of_movies, embedding_size,                 \n                 lr: float = 0.001,\n                b1: float = 0.5,\n                b2: float = 0.999,\n                momentum: float = 0.9,\n                loss_func = mse_loss,\n                sublayer_name = ''):\n        super().__init__()\n        self.save_hyperparameters()\n        self.embedding_layer_users = nn.Embedding(number_of_users, embedding_size)\n        self.embedding_layer_movies = nn.Embedding(number_of_movies, embedding_size)\n        self.loss_func = loss_func\n        \n\n        self.feed_forward = nn.Sequential(\n            nn.Linear(in_features=2 * embedding_size, out_features=64),\n            nn.ReLU(),\n            nn.Linear(in_features=64, out_features=16),\n            nn.ReLU(),\n            nn.Linear(in_features=16, out_features=1), # maybe predict per category?\n            nn.ReLU()\n        )\n        \n    def forward(self, users, movies):\n        raise ('Must be implemented by subclasses')\n    \n    def training_step(self, batch, batch_idx):\n        users, movies, ratings = batch\n        predictions = self(users, movies)\n        loss = self.loss_func(predictions, ratings)\n        self.log(f'{self.hparams.sublayer_name}/train_loss', loss)\n        return loss\n    \n    def validation_step(self, batch, batch_idx):\n        users, movies, ratings = batch\n        predictions = self(users, movies)\n        loss = self.loss_func(predictions, ratings)\n        self.log(f'{self.hparams.sublayer_name}/valid_loss', loss)\n        return loss\n    \n    def configure_optimizers(self):\n        lr = self.hparams.lr\n        b1 = self.hparams.b1\n        b2 = self.hparams.b2\n        weight_decay = 5*1e-4 \n        opt = torch.optim.Adam(self.parameters(), lr=lr, betas=(b1, b2), weight_decay= weight_decay)\n        #scheduler = lr_scheduler.CosineAnnealingLR(opt,T_max=T_max, \n        #                                           eta_min=min_lr)\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(opt,T_0=1, T_mult = 2,\n                                                             eta_min=1e-7)\n        #scheduler = lr_scheduler.ReduceLROnPlateau(opt,\n        #                                           mode='min',\n        #                                          factor=0.1,\n        #                                           patience=7,\n        #                                           threshold=0.0001,\n        #                                           min_lr=min_lr,)\n        \n\n        #scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=100, gamma=0.1)\n        return {\"optimizer\": opt,\n                \"lr_scheduler\": {\n                    \"scheduler\": scheduler,\n                    \"monitor\": \"val_loss\"\n                },\n               }\n    \n    def predict_step(self, batch, batch_idx):\n        users, movies = batch\n        return self(users, movies)\n    \n    def name(self):\n#         todo: name model for saving purposes\n        return f\"BaseNCF_{'Adam'}\"\n\nclass Vanilla_NCF(BaseNCF):\n    def __init__(self, number_of_users, number_of_movies, embedding_size,                 \n                 sublayer_name='vanilla_ncf',\n                 *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.embedding_layer_users = nn.Embedding(number_of_users, embedding_size)\n        self.embedding_layer_movies = nn.Embedding(number_of_movies, embedding_size)\n        \n        self.feed_forward = nn.Sequential(\n            nn.Linear(in_features=2 * embedding_size, out_features=64),\n            nn.ReLU(),\n            nn.Linear(in_features=64, out_features=16),\n            nn.ReLU(),\n            nn.Linear(in_features=16, out_features=1), # maybe predict per category?\n            nn.ReLU()\n        )\n\n    def forward(self, users, movies):\n        users_embedding = self.embedding_layer_users(users)\n        movies_embedding = self.embedding_layer_movies(movies)\n        concat = torch.cat([users_embedding, movies_embedding], dim=1)\n        return torch.squeeze(self.feed_forward(concat))\n    \n   \n    def name(self):\n        return f\"Vanilla_NCF_{'Adam'}\"\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:14:14.374475Z","iopub.execute_input":"2022-04-30T22:14:14.374757Z","iopub.status.idle":"2022-04-30T22:14:15.904668Z","shell.execute_reply.started":"2022-04-30T22:14:14.374727Z","shell.execute_reply":"2022-04-30T22:14:15.903883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GMF(BaseNCF):\n    def __init__(self, number_of_users, number_of_movies, embedding_size,\n                 sublayer_name='gmf',\n                 *args, **kwargs):\n        super(GMF, self).__init__(number_of_users, number_of_movies, embedding_size,)\n        self.embedding_layer_users = nn.Embedding(number_of_users, embedding_size)\n        self.embedding_layer_movies = nn.Embedding(number_of_movies, embedding_size)\n        self.output_layer = nn.Linear(in_features=embedding_size, out_features=1)\n        \n    def forward(self, users, movies):\n        users_embedding = self.embedding_layer_users(users)\n        movies_embedding = self.embedding_layer_movies(movies)\n        return self.output_layer(users_embedding * movies_embedding)    ","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:14:19.97629Z","iopub.execute_input":"2022-04-30T22:14:19.97683Z","iopub.status.idle":"2022-04-30T22:14:21.246924Z","shell.execute_reply.started":"2022-04-30T22:14:19.976796Z","shell.execute_reply":"2022-04-30T22:14:21.246165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MLP(BaseNCF):\n    def __init__(self, number_of_users, number_of_movies, embedding_size,\n                 layer_sizes=[64, 32, 16, 8], # may be used to define feed_forward layer in a more sophisticated way\n                 sublayer_name='mlp',\n                 *args, **kwargs):\n        super(MLP, self).__init__(number_of_users, number_of_movies, embedding_size,)\n        self.embedding_layer_users = nn.Embedding(number_of_users, embedding_size)\n        self.embedding_layer_movies = nn.Embedding(number_of_movies, embedding_size)\n        \n        self.feed_forward = nn.Sequential(\n            nn.Linear(in_features=2 * embedding_size, out_features=64),\n            nn.ReLU(),\n            nn.Linear(in_features=64, out_features=32),\n            nn.ReLU(),\n            nn.Linear(in_features=32, out_features=16), # maybe predict per category?\n            nn.ReLU(),\n            nn.Linear(in_features=16, out_features=8), \n            nn.ReLU()\n        )\n        self.output_layer = nn.Linear(8, 1)\n\n        \n    def forward(self, users, movies):\n        users_embedding = self.embedding_layer_users(users)\n        movies_embedding = self.embedding_layer_movies(movies)\n        concat = torch.cat([users_embedding, movies_embedding], dim=1)\n        hidden_layers = torch.squeeze(self.feed_forward(concat)) \n        return self.output_layer(hidden_layers)\n    \n    # The paper uses VanillaSGD at this layer as they start the GMF and MLP layers pretrained\n    def configure_optimizers(self):\n        lr = self.hparams.lr\n        opt = torch.optim.SGD(self.parameters(), lr=lr)\n        return {\"optimizer\": opt}\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:14:21.248673Z","iopub.execute_input":"2022-04-30T22:14:21.249182Z","iopub.status.idle":"2022-04-30T22:14:22.739672Z","shell.execute_reply.started":"2022-04-30T22:14:21.249144Z","shell.execute_reply":"2022-04-30T22:14:22.738895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NeuMF(BaseNCF):\n    def __init__(self, number_of_users, number_of_movies, embedding_size,                 \n                 lr: float = 0.001,\n#                 b1: float = 0.5,\n#                 b2: float = 0.999,\n#                 momentum: float = 0.9,\n                 alpha = 0.5, # trade-off parameter between two models\n                 gmf_pretrained_ckpt = '',\n                 mlp_pretrained_ckpt = '',\n                 sublayer_name='neumf',\n                 *args, **kwargs):\n        super().__init__( number_of_users, number_of_movies, embedding_size,)\n        \n        self.gmf = GMF.load_from_checkpoint(gmf_pretrained_ckpt); self.gmf.mode = 'train'\n        self.mlp = MLP.load_from_checkpoint(mlp_pretrained_ckpt); self.mlp.mode = 'train'\n        self.output_layer = nn.Linear(in_features=2, out_features=1)\n\n    def forward(self, users, movies):\n        gmf = self.gmf(users, movies)\n        mlp = self.mlp(users, movies)\n        concat = torch.cat([gmf, mlp], dim=1)\n#         todo: implement \\alpha later\n        return self.output_layer(concat)\n    \n   \n    def name(self):\n        return f\"Full_NCF_{'VanillaSGD'}\"\n    \n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:14:22.743069Z","iopub.execute_input":"2022-04-30T22:14:22.743267Z","iopub.status.idle":"2022-04-30T22:14:24.114391Z","shell.execute_reply.started":"2022-04-30T22:14:22.743242Z","shell.execute_reply":"2022-04-30T22:14:24.113693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pretraining & Setup\nPretrain GMF and MLP layers\n\nNOTE: In the sample code, they reform the matrix and calculate a different metric at the end of each epoch, we don't do that currently and only calculate validation loss on a batch.","metadata":{}},{"cell_type":"code","source":"# Parameters\nbatch_size = 1024\nvalid_batch_size = 1024\nnum_epochs = 25\nshow_validation_score_every_epochs = 1\nembedding_size = 16\nlearning_rate = 1e-3\npretrain = False","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:06:50.303022Z","iopub.execute_input":"2022-04-30T22:06:50.303782Z","iopub.status.idle":"2022-04-30T22:06:50.308176Z","shell.execute_reply.started":"2022-04-30T22:06:50.303743Z","shell.execute_reply":"2022-04-30T22:06:50.30726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mse_loss(predictions, target):\n    return torch.mean((predictions - target) ** 2)\n\n# Build Dataloaders\ntrain_users_torch = torch.tensor(train_users, device=device)\ntrain_movies_torch = torch.tensor(train_movies, device=device)\ntrain_predictions_torch = torch.tensor(train_predictions, device=device)\n\ntrain_dataloader = DataLoader(\n    TensorDataset(train_users_torch, train_movies_torch, train_predictions_torch),\n    batch_size=batch_size)\n\ntest_users_torch = torch.tensor(test_users, device=device)\ntest_movies_torch = torch.tensor(test_movies, device=device)\ntest_predictions_torch = torch.tensor(test_predictions, device=device)\n\ntest_dataloader = DataLoader(\n    TensorDataset(test_users_torch, test_movies_torch, test_predictions_torch),\n    batch_size=valid_batch_size)\n\nwandb_logger = WandbLogger(project='cil-project',\n                           log_model='all', \n                           )\nlr_monitor = pl.callbacks.LearningRateMonitor(logging_interval='step')\n# saves a file like: my/path/sample-mnist-epoch=02-val_loss=0.32.ckpt\ncheckpoint_callback = pl.callbacks.ModelCheckpoint(\n    monitor=\"valid_loss\",\n    save_top_k=2,\n    mode=\"min\",\n)\ntrainer = pl.Trainer(callbacks=[checkpoint_callback, lr_monitor], \n#                      gpus=list(range(torch.cuda.device_count())), \n                     gpus=[0], auto_select_gpus=True,\n                     max_epochs=num_epochs, \n                     auto_lr_find=True,\n                     logger=wandb_logger,\n                     log_every_n_steps=5,\n                    )","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:05:34.982903Z","iopub.execute_input":"2022-04-30T22:05:34.983689Z","iopub.status.idle":"2022-04-30T22:05:37.843207Z","shell.execute_reply.started":"2022-04-30T22:05:34.983648Z","shell.execute_reply":"2022-04-30T22:05:37.842455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## VanillaNCF\nUncomment to train VanillaNCF as presented in the sample notebook","metadata":{}},{"cell_type":"code","source":"# as in the sample code\n# ncf = Vanilla_NCF(number_of_users, number_of_movies, embedding_size,\n#          loss_func=mse_loss).to(device)\n# # uncomment to log gradients\n# # wandb_logger.watch(ncf)\n# wandb_logger = WandbLogger(project='cil-project',\n#                            log_model='all', \n#                            name=f'vanilla_ncf_{time.time():.0f}'\n#                            )\n# checkpoint_callback = pl.callbacks.ModelCheckpoint(\n#     monitor=\"vanilla_ncf/valid_loss\",\n#     save_top_k=2,\n#     mode=\"min\",\n# )\n# trainer = pl.Trainer(callbacks=[checkpoint_callback, lr_monitor], \n# #                      gpus=list(range(torch.cuda.device_count())), \n#                      gpus=[0], auto_select_gpus=True,\n#                      max_epochs=num_epochs, \n#                      auto_lr_find=True,\n#                      logger=wandb_logger,\n#                      log_every_n_steps=5,\n#                     )","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:06:31.211976Z","iopub.execute_input":"2022-04-30T22:06:31.212243Z","iopub.status.idle":"2022-04-30T22:06:31.215552Z","shell.execute_reply.started":"2022-04-30T22:06:31.212214Z","shell.execute_reply":"2022-04-30T22:06:31.21484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:06:31.721567Z","iopub.execute_input":"2022-04-30T22:06:31.722049Z","iopub.status.idle":"2022-04-30T22:06:31.725389Z","shell.execute_reply.started":"2022-04-30T22:06:31.722014Z","shell.execute_reply":"2022-04-30T22:06:31.724593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define & Pretrain GMF","metadata":{}},{"cell_type":"code","source":"gmf = GMF(number_of_users, number_of_movies, embedding_size,\n         loss_func=mse_loss).to(device)\n\nwandb_logger = WandbLogger(project='cil-project',\n                           log_model='all', \n                           name=f'gmf_{time.time():.0f}'\n                           )\ncheckpoint_callback = pl.callbacks.ModelCheckpoint(\n    monitor=\"gmf/valid_loss\",\n    save_top_k=2,\n    mode=\"min\",\n)\ntrainer = pl.Trainer(callbacks=[checkpoint_callback, lr_monitor], \n#                      gpus=list(range(torch.cuda.device_count())), \n                     gpus=[0], auto_select_gpus=True,\n                     max_epochs=num_epochs, \n                     auto_lr_find=True,\n                     logger=wandb_logger,\n                     log_every_n_steps=5,\n                    )","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:06:38.788939Z","iopub.execute_input":"2022-04-30T22:06:38.789608Z","iopub.status.idle":"2022-04-30T22:06:38.815196Z","shell.execute_reply.started":"2022-04-30T22:06:38.789566Z","shell.execute_reply":"2022-04-30T22:06:38.814529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if pretrain:\n    print('Starting pretraining GMF module')\n    trainer.fit(gmf,  train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\nelse:\n    print('GMF pretraining skipped')","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:07:27.909001Z","iopub.execute_input":"2022-04-30T22:07:27.909284Z","iopub.status.idle":"2022-04-30T22:07:27.914634Z","shell.execute_reply.started":"2022-04-30T22:07:27.909253Z","shell.execute_reply":"2022-04-30T22:07:27.91391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define & Pretrain MLP","metadata":{}},{"cell_type":"code","source":"mlp = MLP(number_of_users, number_of_movies, embedding_size,\n         loss_func=mse_loss).to(device)\n\nwandb.finish()\nwandb_logger = WandbLogger(project='cil-project',\n                           log_model='all', \n                           name=f'mlp_{time.time():.0f}'\n                           )\ncheckpoint_callback = pl.callbacks.ModelCheckpoint(\n    monitor=\"mlp/valid_loss\",\n    save_top_k=2,\n    mode=\"min\",\n)\n\ntrainer = pl.Trainer(callbacks=[checkpoint_callback, lr_monitor], \n#                      gpus=list(range(torch.cuda.device_count())), \n                     gpus=[0], auto_select_gpus=True,\n                     max_epochs=num_epochs, \n                     auto_lr_find=True,\n                     logger=wandb_logger,\n                     log_every_n_steps=5,\n                    )","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:08:05.060575Z","iopub.execute_input":"2022-04-30T22:08:05.061153Z","iopub.status.idle":"2022-04-30T22:08:05.077901Z","shell.execute_reply.started":"2022-04-30T22:08:05.061111Z","shell.execute_reply":"2022-04-30T22:08:05.077115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if pretrain:\n    print('Starting MLP pretraining.')\n    trainer.fit(mlp,  train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)\nelse:\n    print('MLP pretraining passed.')","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:08:40.043543Z","iopub.execute_input":"2022-04-30T22:08:40.044037Z","iopub.status.idle":"2022-04-30T22:08:40.049352Z","shell.execute_reply.started":"2022-04-30T22:08:40.043998Z","shell.execute_reply":"2022-04-30T22:08:40.048584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Uncomment when running for the first time in a scheduler\n# break","metadata":{"execution":{"iopub.status.busy":"2022-04-29T13:39:58.475576Z","iopub.execute_input":"2022-04-29T13:39:58.47588Z","iopub.status.idle":"2022-04-29T13:39:59.376259Z","shell.execute_reply.started":"2022-04-29T13:39:58.475844Z","shell.execute_reply":"2022-04-29T13:39:59.375214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NeuMF Layer\nDownload pretrained weights and initialize NeuMF layer and train on that","metadata":{}},{"cell_type":"code","source":"wandb.finish()\nrun = wandb.init(project='cil-project')\ngmf_artifact = run.use_artifact('gsaltintas/cil-project/model-19m8lcmr:v8', type='model')\nmlp_artifact = run.use_artifact('gsaltintas/cil-project/model-3t58trbi:v24', type='model')\ngmf_artifact_dir = gmf_artifact.download()\nmlp_artifact_dir = mlp_artifact.download()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:15:52.242229Z","iopub.execute_input":"2022-04-30T22:15:52.24294Z","iopub.status.idle":"2022-04-30T22:16:20.256584Z","shell.execute_reply.started":"2022-04-30T22:15:52.242901Z","shell.execute_reply":"2022-04-30T22:16:20.255606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(gmf_artifact_dir)\nos.path.abspath(os.path.join(gmf_artifact_dir, 'model.ckpt'))","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:09:39.083605Z","iopub.execute_input":"2022-04-30T22:09:39.084006Z","iopub.status.idle":"2022-04-30T22:09:40.497297Z","shell.execute_reply.started":"2022-04-30T22:09:39.083971Z","shell.execute_reply":"2022-04-30T22:09:40.496562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel = NeuMF(number_of_users, number_of_movies, embedding_size,\n              gmf_pretrained_ckpt=os.path.abspath(os.path.join(gmf_artifact_dir, 'model.ckpt')),\n              mlp_pretrained_ckpt=os.path.abspath(os.path.join(mlp_artifact_dir, 'model.ckpt')),\n             loss_func=mse_loss).to(device)\n\nwandb_logger = WandbLogger(project='cil-project',\n                           log_model='all', \n                           name=run\n                           )\ncheckpoint_callback = pl.callbacks.ModelCheckpoint(\n    monitor=\"neumf/valid_loss\",\n    save_top_k=2,\n    mode=\"min\",\n)\ntrainer = pl.Trainer(callbacks=[checkpoint_callback, lr_monitor], \n#                      gpus=list(range(torch.cuda.device_count())), \n                     gpus=[0], auto_select_gpus=True,\n                     max_epochs=num_epochs, \n                     auto_lr_find=True,\n                     logger=wandb_logger,\n                     log_every_n_steps=5,\n                    )","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:16:20.261975Z","iopub.execute_input":"2022-04-30T22:16:20.262204Z","iopub.status.idle":"2022-04-30T22:16:21.642059Z","shell.execute_reply.started":"2022-04-30T22:16:20.262175Z","shell.execute_reply":"2022-04-30T22:16:21.641267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:16:21.643395Z","iopub.execute_input":"2022-04-30T22:16:21.643667Z","iopub.status.idle":"2022-04-30T22:26:35.438282Z","shell.execute_reply.started":"2022-04-30T22:16:21.643631Z","shell.execute_reply":"2022-04-30T22:26:35.437466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit\n## Submission Predictions","metadata":{}},{"cell_type":"code","source":"submission_pd = pd.read_csv('/kaggle/input/cil-collaborative-filtering-2022/sampleSubmission.csv')\nsubmission_users, submission_movies, submission_ratings = extract_users_items_predictions(submission_pd)\nsubmission_users_torch = torch.tensor(submission_users, device=device)\nsubmission_movies_torch = torch.tensor(submission_movies, device=device)\n# create submission dataloader\nsubmit_loader = DataLoader(TensorDataset(submission_users_torch, submission_movies_torch),\n                          batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:26:35.440066Z","iopub.execute_input":"2022-04-30T22:26:35.441895Z","iopub.status.idle":"2022-04-30T22:26:41.581805Z","shell.execute_reply.started":"2022-04-30T22:26:35.441851Z","shell.execute_reply":"2022-04-30T22:26:41.581034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict entries using trainer\nsubmission_predictions = trainer.predict(model, submit_loader)","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:34:36.218537Z","iopub.execute_input":"2022-04-30T22:34:36.221661Z","iopub.status.idle":"2022-04-30T22:34:48.110771Z","shell.execute_reply.started":"2022-04-30T22:34:36.221608Z","shell.execute_reply":"2022-04-30T22:34:48.110033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit\nTransfer predictions for each batch to the data frame (can use model(batch) then trainer.predict for memory efficiency) and then write it to csv.","metadata":{}},{"cell_type":"code","source":"submission_i = 0\nfor pred_batch in submission_predictions:\n    start_ind = submission_i*batch_size\n    end_ind = pred_batch.shape[0] + start_ind\n    submission_pd.iloc[start_ind: end_ind, 1] = np.array(pred_batch.cpu())\n    submission_i += 1","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:34:48.112317Z","iopub.execute_input":"2022-04-30T22:34:48.11411Z","iopub.status.idle":"2022-04-30T22:34:52.807878Z","shell.execute_reply.started":"2022-04-30T22:34:48.11407Z","shell.execute_reply":"2022-04-30T22:34:52.807143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_pd.head, submission_pd.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:34:52.808947Z","iopub.execute_input":"2022-04-30T22:34:52.809176Z","iopub.status.idle":"2022-04-30T22:34:54.174067Z","shell.execute_reply.started":"2022-04-30T22:34:52.809143Z","shell.execute_reply":"2022-04-30T22:34:54.171657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_pd.to_csv('submission.csv', encoding='utf-8' )\n# just in case upload submission to wandb\nwandb.save('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-30T22:33:02.715672Z","iopub.execute_input":"2022-04-30T22:33:02.716227Z","iopub.status.idle":"2022-04-30T22:33:08.796553Z","shell.execute_reply.started":"2022-04-30T22:33:02.716189Z","shell.execute_reply":"2022-04-30T22:33:08.794888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}